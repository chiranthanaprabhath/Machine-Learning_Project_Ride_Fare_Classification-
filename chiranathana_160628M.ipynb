{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'StratifiedShuffleSplit' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-66bfc146f5e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#all data set which is 16968 rows × 7 columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mGradientBoost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mGradientBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'StratifiedShuffleSplit' object is not iterable"
     ]
    }
   ],
   "source": [
    "# import all nessary labaries\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def convertRadian(dr):\n",
    "    return (dr*math.pi)/180\n",
    "\n",
    "DataTrain = pd.read_csv('train.csv')\n",
    "DataTrain['label'] = DataTrain['label'].map({'correct': 1, 'incorrect': 0})\n",
    "DataTrain = DataTrain.dropna()\n",
    "DataTrain = DataTrain.drop(['pickup_time','drop_time'], axis = 1)\n",
    "DataTrain['DrivingT']=DataTrain['duration']+DataTrain['meter_waiting']\n",
    "DataTrain['DrivingF']=DataTrain['fare']-DataTrain['meter_waiting_fare']-DataTrain['additional_fare']\n",
    "\n",
    "DataTrain['pick_lat'] = convertRadian(DataTrain['pick_lat'])\n",
    "DataTrain['pick_lon'] = convertRadian(DataTrain['pick_lon'])\n",
    "DataTrain['drop_lat'] = convertRadian(DataTrain['drop_lat'])\n",
    "DataTrain['drop_lon'] = convertRadian(DataTrain['drop_lon'])\n",
    "dlon = DataTrain['drop_lon'] - DataTrain['pick_lon']\n",
    "dlat = DataTrain['drop_lat'] - DataTrain['pick_lat']\n",
    "DataTrain['dist'] = np.sin(dlat/2)**2 + np.cos(DataTrain['pick_lat'])*np.cos(DataTrain['drop_lat'])*np.sin(dlon/2)**2\n",
    "DataTrain['dist'] = 2*np.arctan2(DataTrain['dist']**0.5,(1-DataTrain['dist'])**0.5)\n",
    "R = 6373.0\n",
    "DataTrain['dist'] = R*DataTrain['dist']\n",
    "\n",
    "DataTrain = DataTrain.drop(['tripid','pick_lat','pick_lon','drop_lat','drop_lon'], axis = 1)\n",
    "y = DataTrain['label']\n",
    "X = DataTrain.drop(['label'],axis=1)#all data set which is 16968 rows × 7 columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3) \n",
    "GradientBoost = GradientBoostingClassifier(n_estimators=600,learning_rate=0.5, max_features=2, max_depth=2,  random_state=0)\n",
    "GradientBoost.fit(X_train, y_train) \n",
    "y_pred = GradientBoost.predict(X_test)\n",
    "GradientBoost_score = f1_score(y_test, y_pred)\n",
    "print(\"Training----------\")\n",
    "print(\"Gradient Boost F1 score = {}\".format(f1_score(y_test, y_pred)))#print Accuracy of F1 score\n",
    "\n",
    "CalibratedCV = CalibratedClassifierCV(GaussianNB(), cv=4, method='sigmoid')\n",
    "CalibratedCV.fit(X_train, y_train) \n",
    "y_pred = CalibratedCV.predict(X_test)\n",
    "\n",
    "\n",
    "CalibratedCV_score = f1_score(y_test, y_pred)\n",
    "print(\"CalibratedCV F1 score = {}\".format(f1_score(y_test, y_pred)))##print Accuracy of F1 score\n",
    "\n",
    "XGB = XGBClassifier(n_estimators=1200,gamma=0.6,learning_rate=0.01)\n",
    "XGB.fit(X_train, y_train) \n",
    "y_pred = XGB.predict(X_test)\n",
    "XGB_score = f1_score(y_test, y_pred)\n",
    "print(\"XGboost F1 score = {}\".format(f1_score(y_test, y_pred)))#print Accuracy of F1 score\n",
    "\n",
    "\n",
    "# group / ensemble of models \n",
    "estimator = [] \n",
    "estimator.append(('GradientBoost', GradientBoost)) \n",
    "estimator.append(('CalibratedCV', CalibratedCV)) \n",
    "estimator.append(('XGB', XGB))\n",
    "\n",
    "vot_hard = VotingClassifier(estimators = estimator, voting ='hard') \n",
    "vot_hard.fit(X_train, y_train) \n",
    "y_pred = vot_hard.predict(X_test) \n",
    "\n",
    "# using accuracy_score metric to predict accuracy\n",
    "hard_score = f1_score(y_test, y_pred)\n",
    "print(\"Hard voting F1 score = {}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "# Voting Classifier with soft voting \n",
    "vot_soft = VotingClassifier(estimators = estimator, voting ='soft') \n",
    "vot_soft.fit(X_train, y_train) \n",
    "y_pred = vot_soft.predict(X_test)  \n",
    "# using accuracy_score \n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "soft_score = f1_score(y_test, y_pred)\n",
    "print(\"Testing----------\")\n",
    "print(\"Soft voting score = {}\".format(f1_score(y_test, y_pred)))\n",
    "print(\"GradientBoost score = {}\".format(GradientBoost_score))\n",
    "print(\"CalibratedCV score = {}\".format(CalibratedCV_score))\n",
    "print(\"XGB score = {}\".format(XGB_score))\n",
    "print(\"Hard voting score = {}\".format(hard_score))\n",
    "print(\"Soft voting score = {}\".format(soft_score))\n",
    "\n",
    "DataTest = pd.read_csv('test.csv')\n",
    "DataTest = DataTest.dropna()\n",
    "DataTest = DataTest.drop(['pickup_time','drop_time'], axis = 1)\n",
    "DataTest['DrivingT']=DataTest['duration']+DataTest['meter_waiting']\n",
    "DataTest['DrivingF']=DataTest['fare']-DataTest['meter_waiting_fare']-DataTest['additional_fare']\n",
    "\n",
    "DataTest['pick_lat'] = convertRadian(DataTest['pick_lat'])\n",
    "DataTest['pick_lon'] = convertRadian(DataTest['pick_lon'])\n",
    "DataTest['drop_lat'] = convertRadian(DataTest['drop_lat'])\n",
    "DataTest['drop_lon'] = convertRadian(DataTest['drop_lon'])\n",
    "dlon = DataTest['drop_lon'] - DataTest['pick_lon']\n",
    "dlat = DataTest['drop_lat'] - DataTest['pick_lat']\n",
    "DataTest['dist'] = np.sin(dlat/2)**2 + np.cos(DataTest['pick_lat'])*np.cos(DataTest['drop_lat'])*np.sin(dlon/2)**2\n",
    "DataTest['dist'] = 2*np.arctan2(DataTest['dist']**0.5,(1-DataTest['dist'])**0.5)\n",
    "R = 6373.0\n",
    "DataTest['dist'] = R*DataTest['dist']\n",
    "DataTest = DataTest.drop(['tripid','pick_lat','pick_lon','drop_lat','drop_lon'], axis = 1) \n",
    "X1 = DataTest\n",
    "\n",
    "yhat = vot_soft.predict(X1)\n",
    "\n",
    "fileData_test = pd.read_csv('test.csv')\n",
    "fileData_test =fileData_test.drop(['meter_waiting_till_pickup','pickup_time','drop_time','pick_lat','pick_lon','drop_lat','drop_lon'], axis = 1)\n",
    "fileData_new = fileData_test\n",
    "fileData_new = fileData_new.drop(['additional_fare','duration','meter_waiting','meter_waiting_fare','fare'], axis = 1) \n",
    "fileData_new['prediction'] = yhat\n",
    "fileData_new['prediction'].value_counts()\n",
    "fileData_new.to_csv(\"final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
